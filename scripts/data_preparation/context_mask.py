import pandas as pd
import random
import os
import argparse

# Set fixed random seed for reproducibility
# è®¾ç½®å›ºå®šéšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
RANDOM_SEED = 42
random.seed(RANDOM_SEED)

def apply_masking(row, mask_ratio, mask_token, random_seed):
    """Apply masking to the scrambled context while preserving the target token.
    å¯¹æ‰“ä¹±çš„ä¸Šä¸‹æ–‡è¿›è¡Œé®ç›–ï¼ŒåŒæ—¶ä¿ç•™ç›®æ ‡è¯token
    
    Args:
        row (pd.Series): Input data row containing scrambled_context and scrambled_token
        mask_ratio (float): Ratio of words to mask (0.0-1.0)
        mask_token (str): Token used for masking
        random_seed (int): Random seed for reproducibility
        
    Returns:
        str: Masked context
    """
    # Handle missing data case
    # å¤„ç†æ•°æ®ç¼ºå¤±çš„æƒ…å†µ
    if pd.isna(row["scrambled_context"]) or pd.isna(row["scrambled_token"]):
        row["success"] = False
        return row["scrambled_context"]

    words = row["scrambled_context"].split()
    target_token = row["scrambled_token"]

    # Verify target token exists in context
    # éªŒè¯ç›®æ ‡è¯æ˜¯å¦å­˜åœ¨äºä¸Šä¸‹æ–‡ä¸­
    if target_token not in words:
        row["success"] = False
        return row["scrambled_context"]

    # Find maskable word indices (excluding target token)
    # æ‰¾å‡ºå¯ä»¥é®ç›–çš„è¯ç´¢å¼•ï¼ˆæ’é™¤ç›®æ ‡è¯ï¼‰
    candidate_indices = [i for i, word in enumerate(words) if word != target_token]

    # Calculate number of words to mask
    # è®¡ç®—éœ€è¦é®ç›–çš„è¯æ•°é‡
    num_to_mask = int(len(candidate_indices) * mask_ratio)

    # Select indices to mask using fixed random seed
    # ä½¿ç”¨å›ºå®šéšæœºç§å­é€‰æ‹©è¦é®ç›–çš„è¯ç´¢å¼•
    random.seed(random_seed)
    mask_indices = random.sample(candidate_indices, num_to_mask)

    # Apply masking
    # åº”ç”¨é®ç›–
    masked_words = [mask_token if i in mask_indices else word for i, word in enumerate(words)]
    
    return " ".join(masked_words)

def main():
    """Main function to process SQuAD dataset with typoglycemia masking
    ä¸»å‡½æ•°ï¼šå¤„ç†å¸¦æœ‰è¯åºæ‰“ä¹±é®ç›–çš„SQuADæ•°æ®é›†
    """
    parser = argparse.ArgumentParser(description="Generate masked versions of SQuAD typoglycemia dataset")
    parser.add_argument("--scale", type=str, default="1000", 
                       help="Dataset scale (e.g., '20000' for 20k samples)")
    args = parser.parse_args()

    # Configuration parameters
    # é…ç½®å‚æ•°
    scramble_levels = ["0", "0.25", "0.5", "0.75", "1.0"]  # Scrambling ratios / æ‰“ä¹±æ¯”ä¾‹
    mask_ratios = [0.0, 0.25, 0.5, 0.75, 1.0]  # Context masking ratios / ä¸Šä¸‹æ–‡é®ç›–æ¯”ä¾‹
    MASK_TOKEN = "_"  # Special masking token / ç‰¹æ®Šé®ç›–ç¬¦å·

    # Path templates
    # è·¯å¾„æ¨¡æ¿
    input_path_template = "dataset/squad_{}_fixed/squad_{}_scramble_{}_fixed.csv"
    output_path_template = "dataset/squad_{}_mask_seed_{}/squad_{}_scramble_{}_mask_{}.csv"

    # Process each scramble level
    # å¤„ç†æ¯ç§æ‰“ä¹±ç¨‹åº¦çš„æ•°æ®
    for scramble in scramble_levels:
        input_path = input_path_template.format(args.scale, args.scale, scramble)
        df = pd.read_csv(input_path)
        
        initial_success_count = df["success"].sum()
        total_samples = len(df)

        # Process each masking ratio
        # å¤„ç†æ¯ç§é®ç›–æ¯”ä¾‹
        for mask_ratio in mask_ratios:
            df_masked = df.copy()
            
            # Apply masking to each row
            # å¯¹æ¯ä¸€è¡Œåº”ç”¨é®ç›–
            df_masked["mask_context"] = df_masked.apply(
                lambda row: apply_masking(row, mask_ratio, MASK_TOKEN, RANDOM_SEED), 
                axis=1
            )

            # Update success status
            # æ›´æ–°å¤„ç†æˆåŠŸçŠ¶æ€
            if mask_ratio != 0.0:
                df_masked.loc[df_masked["mask_context"] == df_masked["scrambled_context"], "success"] = False
            df_masked = df_masked[df_masked["success"] == True]

            # Calculate statistics
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            final_success_count = len(df_masked)
            failure_count = total_samples - final_success_count
            success_rate = (final_success_count / total_samples) * 100
            success_loss = initial_success_count - final_success_count

            # Save processed data
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            output_path = output_path_template.format(
                args.scale, RANDOM_SEED, args.scale, scramble, mask_ratio
            )
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            df_masked.to_csv(output_path, index=False)

            # Print statistics
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"âœ… Generated file: {output_path}")
            print(f"   - Initial successful samples: {initial_success_count}")
            print(f"   - Final successful samples: {final_success_count}")
            print(f"   - Lost successful samples: {success_loss}")
            print(f"   - Failed samples: {failure_count}")
            print(f"   - Total samples: {total_samples}")
            print(f"   - Success rate: {success_rate:.2f}%\n")

    print(f"ğŸ‰ All {len(scramble_levels) * len(mask_ratios)} files generated successfully! (Reproducible with seed {RANDOM_SEED})")

if __name__ == "__main__":
    main()